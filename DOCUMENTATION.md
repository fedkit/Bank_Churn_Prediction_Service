
Сервис для предсказания оттока (churn) клиентов банка. Состоит из:

1. Бэкенда на **FastAPI** (файл `backend.py`).
    
2. Веб-интерфейса на **Streamlit** (файл `streamlit_app.py`).
    
3. Конфигурационных файлов для Docker (в том числе `docker-compose.yml`, `Dockerfile.backend`, `Dockerfile.streamlit`).
    
4. Папок `models` и `train_models` (в `models` хранятся обученные модели, а в `train_models` находиться код, отвечающий за тренировку и сохранение этих моделей).
    
5. `requirements.txt` со списком необходимых Python-библиотек.


## 1. Описание основных компонентов

### 1.1. Бэкенд (FastAPI)

- **Файл**: `backend.py`
    
- **Функционал**:
    
    - Принимает запросы с информацией о клиентах.
        
    - Загружает заранее обученные модели (по одной для каждой страны: Франция, Германия, Испания).
        
    - Выполняет предобработку поступающих данных и формирует предсказания вероятности оттока (churn).
        
    - Возвращает результат в формате JSON.
        
- **Ключевые эндпоинты**:
    
    1. `POST /predict_batch` — пакетное предсказание (принимает список клиентов и возвращает для каждого клиента вероятность оттока и бинарный результат).
        
    2. `GET /feature_importances` — возвращает важность признаков для выбранной модели (страны).
        

### 1.2. Веб-интерфейс (Streamlit)

- **Файл**: `streamlit_app.py`
    
- **Функционал**:
    
    - Графический интерфейс для загрузки файлов CSV, отправки данных на предикт и отображения результатов.
        
    - Отображает статистику и простую аналитику (распределение по странам, полу и т.д.).
        
    - Позволяет скачать результаты предсказания в формате CSV.
        
    - Настройки параметров запуска Streamlit (порт 8501, отключён CORS).
        

### 1.3. Docker-файлы

1. **`docker-compose.yml`**
    
    - Основной файл docker-compose для запуска двух сервисов: `backend` и `streamlit`.
        
    - Пробрасывает порты `8000` для бэкенда и `8501` для веб-интерфейса.
        
    - Монтирует папку `models` в контейнер бэкенда, чтобы у него был доступ к обученным моделям.
        
2. **`Dockerfile.backend`**
    
    - Формирует образ для бэкенда.
        
    - Использует Python 3.9-slim.
        
    - Копирует `requirements.txt`, устанавливает все необходимые зависимости.
        
    - Копирует `backend.py` и модели в контейнер.
        
    - Запускает приложение через `uvicorn` на порту 8000.
        
3. **`Dockerfile.streamlit`**
    
    - Формирует образ для приложения Streamlit.
        
    - Аналогично использует Python 3.9-slim.
        
    - Копирует `requirements.txt`, устанавливает зависимости.
        
    - Копирует `streamlit_app.py` и запускает Streamlit.
        

### 1.4. Файл зависимостей `requirements.txt`

Содержит версии необходимых библиотек (FastAPI, Streamlit, pandas, joblib и т.д.).

### 1.5. Папки с моделями и кодом для обучения

- **`models`** — хранит файлы с сериализованными моделями (файлы `.pkl`), а также значения порогов (threshold).
    
- **`train_models`** — сожержит Jupyter Notebook или Python-скрипты для обучения, валидации и сохранения моделей.
    

---

## 2. Инструкция по локальному запуску без Docker

1. **Склонировать репозиторий** (или скопировать содержимое проекта) в удобное место:
    
    ```bash
    git clone <URL-ВАШЕГО-РЕПОЗИТОРИЯ>
    cd bank_churn_prediction_service
    ```
    
2. **Создать и активировать виртуальное окружение** (опционально, но настоятельно рекомендуется):
    
    ```bash
    python -m venv venv
    source venv/bin/activate  # на Linux/Mac
    # или 
    venv\Scripts\activate     # на Windows
    ```
    
3. **Установить зависимости**:
    
    ```bash
    pip install --upgrade pip
    pip install -r requirements.txt
    ```
    
4. **Запуск бэкенда** (FastAPI):
    
    ```bash
    uvicorn backend:app --host 0.0.0.0 --port 8000
    ```
    
    - По умолчанию приложение будет доступно по адресу [http://localhost:8000](http://localhost:8000/).
        
5. **Запуск фронтенда** (Streamlit) в другом терминале:
    
    ```bash
    streamlit run streamlit_app.py --server.port 8501
    ```
    
    - Откройте в браузере [http://localhost:8501](http://localhost:8501/), чтобы увидеть веб-интерфейс.
        
6. **Проверка работы**:
    
    - Перейдите по адресу [http://localhost:8000/docs](http://localhost:8000/docs), чтобы посмотреть интерактивную документацию FastAPI (Swagger).
        
    - Перейдите по адресу [http://localhost:8501](http://localhost:8501/), чтобы увидеть Streamlit-приложение.
        

---

## 3. Запуск с помощью Docker и docker-compose

### 3.1. Подготовка

Убедитесь, что у вас установлены:

- Docker (версия не ниже 20.x).
    
- docker-compose (версия не ниже 1.29).
    

### 3.2. Сборка и запуск сервисов

1. **Склонировать репозиторий** (если не сделали это ранее):
    
    ```bash
    git clone <URL-ВАШЕГО-РЕПОЗИТОРИЯ>
    cd bank_churn_prediction_service
    ```
    
2. **Собрать образы** и запустить контейнеры (запуск в фоновом режиме):
    
    ```bash
    docker-compose up --build -d
    ```
    
    - Параметр `--build` пересобирает образы на основе `Dockerfile.backend` и `Dockerfile.streamlit`.
        
    - Флаг `-d` запускает контейнеры в фоновом режиме.
        
3. **Проверить статус контейнеров**:
    
    ```bash
    docker-compose ps
    ```
    
    Вы увидите два сервиса: `backend` (порт 8000) и `streamlit` (порт 8501).
    
4. **Открыть веб-интерфейс**:
    
    - Перейдите в браузере по адресу [http://localhost:8501](http://localhost:8501/).
        
    - Бэкенд доступен по адресу [http://localhost:8000](http://localhost:8000/).
        
    - Интерфейс документации FastAPI: [http://localhost:8000/docs](http://localhost:8000/docs).
        
5. **Остановить и удалить контейнеры** (при необходимости):
    
    ```bash
    docker-compose down
    ```
    

---

## 4. Описание эндпоинтов API

Ниже приведено описание основных маршрутов **FastAPI**-приложения.

1. **`POST /predict_batch`**
    
    - **Описание**:  
        Выполняет пакетное предсказание на входных данных. Принимает JSON с ключом `"clients"`, содержащим список клиентов.
        
    - **Формат запроса**:
        
        ```json
        {
          "clients": [
            {
              "CustomerId": 15634602,
              "Geography": "France",
              "CreditScore": 619,
              "Age": 42,
              "Tenure": 2,
              "Balance": 0.00,
              "NumOfProducts": 1,
              "HasCrCard": 1,
              "IsActiveMember": 1,
              "EstimatedSalary": 101348.88,
              "Gender": "Male" 
            },
            ...
          ]
        }
        ```
        
    - **Формат ответа** (пример):
        
        ```json
        [
          {
            "CustomerId": 15634602,
            "Geography": "France",
            "prediction": 0,
            "churn_probability": 0.1928
          },
          ...
        ]
        ```
        
        Где:
        
        - `prediction` — бинарный флаг (0: клиент останется, 1: клиент уйдёт),
            
        - `churn_probability` — вероятность оттока (число от 0 до 1).
            
2. **`GET /feature_importances`**
    
    - **Описание**:  
        Возвращает важность признаков для выбранной страны (по умолчанию `France`).
        
    - **Пример запроса**:
        
        ```bash
        GET /feature_importances?country=France
        ```
        
    - **Пример ответа**:
        
        ```json
        {
          "Кредитный рейтинг": 0.037,
          "Возраст": 0.274,
          "Стаж (лет)": 0.046,
          "Баланс": 0.114,
          "Кол-во продуктов": 0.019,
          "Наличие кредитной карты": 0.005,
          "Активность": 0.192,
          "Оценочная зарплата": 0.033,
          "Пол": 0.280
        }
        ```
        

---

## 5. Руководство по структуре проекта

```
bank_churn_prediction_service/
├── models/
│   ├── model_france.pkl
│   ├── model_spain.pkl
│   └── model_germany.pkl
├── train_models/
│   └── ... (скрипты/ноутбуки для обучения)
├── venv/ (виртуальное окружение Python, опционально)
├── backend.py            (код бэкенда на FastAPI)
├── docker-compose.yml    (основной docker-compose файл)
├── Dockerfile.backend    (Dockerfile для бэкенда)
├── Dockerfile.streamlit  (Dockerfile для фронтенда)
├── requirements.txt      (список зависимостей)
└── streamlit_app.py      (код веб-приложения на Streamlit)
```

- **models/**: содержит сериализованные модели в формате `.pkl`. Каждая модель — это словарь, где:
    
    - `"model"` — обученная модель (например, XGBoost),
        
    - `"threshold"` — числовой порог, выше которого вероятность оттока считается достаточной для присвоения `prediction=1`.
        
- **train_models/**: хранится Jupyter Notebook, с помощью которых проводилось обучение моделей, их валидация и сохранение.
    
- **backend.py**:
    
    - Основная бизнес-логика бэкенда.
        
    - Загрузка моделей из `models/`.
        
    - Предобработка и валидация входящих данных (`validate_and_preprocess_input`).
        
    - Формирование предсказаний с учётом порогов (`threshold`).
        
- **docker-compose.yml**:
    
    - Описывает два сервиса: `backend` (FastAPI) и `streamlit`.
        
    - Пробрасывает порты 8000 и 8501.
        
    - Монтирует локальную директорию `./models` в `/app/models` контейнера бэкенда.
        
- **Dockerfile.backend**:
    
    - Собирает образ на основе `python:3.9-slim`.
        
    - Устанавливает зависимости и запускает `uvicorn` на 8000 порту.
        
- **Dockerfile.streamlit**:
    
    - Собирает образ на основе `python:3.9-slim`.
        
    - Устанавливает зависимости и запускает Streamlit на 8501 порту.
        
- **requirements.txt**:
    
    - Перечислены конкретные версии библиотек (FastAPI, pandas, joblib, Streamlit, и т.д.).
        
- **streamlit_app.py**:
    
    - Веб-интерфейс для загрузки данных, отправки их на предикт, визуализации результатов и аналитики.
        
    - Использует модуль `requests` для отправки запросов на эндпоинты бэкенда.
        
    - Даёт возможность скачать полученные результаты и посмотреть важности признаков.
        

---

## 6. Советы по дообучению / изменению моделей

- Все обученные модели лежат в `models/`.
    
- При замене моделей убедитесь, что сохраняете их в формате, аналогичном `model_france.pkl`, `model_spain.pkl`, `model_germany.pkl`:
    
    ```python
    model_bundle = {
        "model": trained_model,
        "threshold": 0.5  # пример порога
    }
    joblib.dump(model_bundle, "model_france.pkl")
    ```
    
- Следите за тем, чтобы набор входных признаков оставался тем же самым, что и в коде предобработки (функция `validate_and_preprocess_input` внутри `backend.py`).
    

---

## 7. Часто встречающиеся проблемы и пути их решения

1. **Ошибка при загрузке файла CSV в Streamlit**  
    Убедитесь, что файл действительно CSV (например, `data.csv`), и в нём есть все обязательные столбцы:
    
    - `CustomerId`, `Geography`, `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts`, `HasCrCard`, `IsActiveMember`, `EstimatedSalary`, а также `Gender` или `Gender_Male`.
        
2. **Модели не найдены** (`file not found` / `No such file or directory`)  
    Проверьте путь к файлам моделей и что они действительно лежат в папке `models/`.  
    Убедитесь, что при запуске Docker, папка `models` монтируется корректно (см. `volumes` в `docker-compose.yml`).
    
3. **Streamlit-приложение не видит бэкенд**
    
    - Если используете Docker, в коде `streamlit_app.py` переменная `API_URL` должна указывать на `http://backend:8000`.
        
    - Если запускаете локально, укажите `http://localhost:8000`.
        
4. **Не установлены необходимые зависимости**
    
    - Выполните команду `pip install -r requirements.txt` или пересоберите Docker-образы (`docker-compose up --build`).
        

---

## 8. Поддержка и обратная связь

Если у вас есть вопросы или пожелания по развитию проекта:

1. Создайте [Issue](https://github.com/Radikq/Bank_Churn_Prediction_Service/issues) в GitHub (если проект доступен там).
    
2. Свяжитесь со мной в телеграмм (@radikq1).
    

---

**Удачной работы с сервисом!** Надеюсь, данная документация поможет вам в быстром и удобном запуске и использовании системы прогнозирования оттока клиентов банка.
